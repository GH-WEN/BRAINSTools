#!/bin/env python
# \author Hans J. Johnson

import sys
import SimpleITK as sitk
import os
import shutil
import pandas as pd
import json

from lut_config.condensed_data_prep_utils import *

import collections

from joblib import Parallel, delayed
import multiprocessing

num_cores = multiprocessing.cpu_count()

# pd.set_option('display.height', 1000)
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)

EXPERIMENT_DIR='/localscratch/Users/johnsonhj/20181002_LesionMappingBAW'
EXPERIMENT_NAME='20190207_niftinet_data_inputs'
OUTPUT_PREFIX = "images_optimized"
OUT_DIR = os.path.join(EXPERIMENT_DIR,EXPERIMENT_NAME,OUTPUT_PREFIX)


WORK_DIR = os.path.join(EXPERIMENT_DIR,"UIOWA2018_LesionMapping/nifti_net_220_full_labelmap_config")

## HINTS FOR PATHING /localscratch/Users/johnsonhj/20181002_LesionMappingBAW/UIOWA2018_LesionMapping/all_lesion_tissueclassify_dirs.list
ALL_LESIONS_DRIVER_LIST=os.path.join(EXPERIMENT_DIR,'UIOWA2018_LesionMapping/all_lesion_tissueclassify_dirs.list')

BAW_ATLAS_MAPPING = os.path.join(EXPERIMENT_DIR,'UIOWA2018_LesionMapping/BAWHDAdultAtlas_FreeSurferConventionColorLUT_20160524.txt')
# BAW produces ushort images with numbers that have gaps,  For deep learning, we need a compact set of labels starting at 0
# to simplify the coding/decoding

# This list (with zero added generated by querying all the label maps)
GLBL_FOUND_LBL_VALUES=sorted([0,1024, 1025, 1026, 1027, 4, 5, 1028, 7, 8, 1029, 10, 11, 12, 13, 1030, 15, 16, 17, 18,
                              1034, 1035, 14, 24, 26, 28, 31, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 1018, 58, 60,
                              63, 1031, 2116, 1032, 1033, 2129, 85, 1116, 98, 1129, 120, 123, 128, 129, 130, 143, 251,
                              252, 253, 254, 255, 999, 2018, 600, 2020, 15000, 15001, 2021, 1017, 2035, 2022, 1015,
                              15071, 15072, 15073, 2024, 2033, 3005, 3007, 4026, 15140, 15141, 15142, 15143, 15144,
                              15145, 3009, 15150, 15151, 15156, 15157, 15160, 15161, 15162, 15163, 15164, 15165, 3013,
                              4032, 1016, 15172, 15173, 15174, 15175, 15178, 15179, 15184, 15185, 15190, 15191, 15192,
                              15193, 15194, 15195, 15200, 15201, 3021, 3023, 2006, 2007, 2030, 3028, 5001, 5002, 1013,
                              3033, 4001, 4002, 4003, 3034, 4005, 4006, 4007, 4008, 4009, 4010, 4011, 4012, 4013, 4014,
                              4015, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 3001, 3002, 4027, 4025, 4028,
                              4029, 4031, 3006, 4030, 4034, 4035, 3003, 4033, 3014, 3015, 3010, 3008, 3018, 3011, 3012,
                              3019, 3022, 3016, 2000, 3017, 3020, 3024, 3025, 2005, 3029, 3030, 2008, 2009, 2002, 3026,
                              3027, 3031, 2014, 3032, 2010, 3035, 2012, 2013, 2011, 2015, 2016, 2017, 2019, 2025, 1002,
                              2026, 2027, 1005, 2029, 1007, 2031, 1000, 1006, 2028, 2032, 1008, 1009, 1010, 1011, 2034,
                              1012, 1019, 1020, 1021, 1022, 1014]
                             )
with open("oldToNewIndexMapping.json",'r') as jfid:
  json_read = json.load(jfid)
  GLBL_BAW_TO_COMPACT_MAPPING = dict()
  for k,v in json_read.items():
    GLBL_BAW_TO_COMPACT_MAPPING[int(k)] = v
  # Use NewIndexMapping_LUT.txt to view items recoded by this scheme.

outputLUT=os.path.join(OUT_DIR, "NewIndexMapping_LUT.txt")
if not os.path.exists(outputLUT):
    shutil.copy("NewIndexMapping_LUT.txt", outputLUT)

with open(ALL_LESIONS_DRIVER_LIST,'r') as fid:
    # find /Shared/sinapse/CACHE/20181002_LesionMapping_base_Results /Shared/paulsen/Experiments/20160520_PREDICTHD_long_Results -name "TissueClassify" -type d > all_lesion_tissueclassify_dirs.list
    all_base_baw_dirs = [x.strip().replace("/TissueClassify", "") for x in fid.readlines()]
    #all_base_baw_dirs = all_base_baw_dirs[1:500]


# subj_list = []
def process_one_session(base_path):
    missing=list()
    path_elements = base_path.split('/')
    # base_path= base_path # os.path.join('/',*path_elements[0:-3])
    # proj = path_elements[-3]
    subj = path_elements[-2]
    sess = path_elements[-1]
    # if subj in subj_list:
    #     continue # only one sample per subject for now
    # subj_list.append(subj)
    t1w_name = os.path.join(base_path, 'TissueClassify', 't1_average_BRAINSABC.nii.gz')
    t2w_name = os.path.join(base_path, 'TissueClassify', 't2_average_BRAINSABC.nii.gz')
    lbs_name = os.path.join(base_path, 'JointFusion', 'JointFusion_HDAtlas20_2015_dustCleaned_label.nii.gz')
    head_lbls_name = os.path.join(base_path, 'TissueClassify', 'fixed_headlabels_seg.nii.gz')
    air_lbl_name = os.path.join(base_path, 'TissueClassify', 'POSTERIOR_AIR.nii.gz')
    fcsv_name = os.path.join(base_path, 'ACPCAlign', 'BCD_ACPC_Landmarks.fcsv')
    if not os.path.exists(t1w_name):
        missing.append(t1w_name)
    if not os.path.exists(lbs_name):
        missing.append(lbs_name)
    if not os.path.exists(air_lbl_name):
        missing.append(air_lbl_name)
    if not os.path.exists(head_lbls_name):
        missing.append(head_lbls_name)
    if len(missing) > 0:
        print("MISSING {0}".format(missing))
    if os.path.exists(t1w_name) and os.path.exists(lbs_name):
        fcsv_link_name = os.path.join(OUT_DIR, "{0}_{1}.fcsv".format(subj, sess))
        if not os.path.exists(fcsv_link_name):
            shutil.copyfile(fcsv_name, fcsv_link_name)

        mincutoff =  getMinCutOff(fcsv_link_name)
        def read_and_chop_image( imfname, min_value):
          """
          :param imfname: Filename of image to read
          :param min_value: Min cutoff point identifier
          :return:
          """
          im = sitk.ReadImage(imfname, sitk.sitkUInt16)
          return ChopImageIndexesBelowZPoint(im, min_value)

        t1w_link_name = os.path.join(OUT_DIR, "{0}_{1}_{2}.nii.gz".format(subj, sess, 't1w'))
        t2w_link_name = os.path.join(OUT_DIR, "{0}_{1}_{2}.nii.gz".format(subj, sess, 't2w'))


        t1w_inimg = read_and_chop_image(t1w_name, mincutoff)
        t1w_inimg = resample_256_iso(t1w_inimg + 1, sitk.sitkLinear)
        fov_mask = (t1w_inimg > 0)

        if os.path.exists(t2w_name):
            t2w_inimg = read_and_chop_image(t2w_name, mincutoff)
            t2w_inimg = resample_256_iso(t2w_inimg + 1, sitk.sitkLinear)
            fov_mask = fov_mask * (t2w_inimg > 0)

        if not os.path.exists(t1w_link_name):
            WriteImageUInt8(t1w_inimg, t1w_link_name, True)
        if os.path.exists(t2w_name) and not os.path.exists(t2w_link_name):
              WriteImageUInt8(t2w_inimg, t2w_link_name, True)

## Process the label maps
        lbs_link_name = os.path.join(OUT_DIR, "{0}_{1}_{2}.nii.gz".format(subj, sess, 'dense_seg'))
        lesion_cropped_link_name = os.path.join(OUT_DIR, "{0}_{1}_{2}.nii.gz".format(subj, sess, 'lesion_seg'))

        if not os.path.exists(lbs_link_name) or not os.path.exists(lesion_cropped_link_name):
            head_fixed_remapper = {
                9: 123,  # 9 muscle: 123,Muscle,238,0,0,255
                8: 120,  # 8 fat  120,SC-Fat-Muscle,238,238,209,255
                7: 129,  # 7 bone 129,Bone,30,144,255,255
                6: 143,  # 6 vitrous humor 143,Vitreous-Humor,255,255,254,255
                4: 24  # 24, CSF, 60, 60, 60, 255
            }

            head_lm = sitk.ReadImage(head_lbls_name, sitk.sitkUInt16)
            head_lm = head_lm * sitk.Cast((head_lm >= 5) * (head_lm <= 9) * (head_lm != 5), sitk.sitkUInt16)
            head_lm = lblmap_renumber(head_lm, head_fixed_remapper)
            head_lm = ChopImageIndexesBelowZPoint(head_lm, mincutoff)
            head_lm = resample_256_iso(head_lm, sitk.sitkNearestNeighbor)

            AIR_VALUE = 130  # 130,Air,147,19,173,255 ()
            air_lm = sitk.Cast(sitk.ReadImage(air_lbl_name, sitk.sitkFloat32) > 0.50, sitk.sitkUInt16) * AIR_VALUE
            air_lm = ChopImageIndexesBelowZPoint(air_lm, mincutoff)
            air_lm = resample_256_iso(air_lm, sitk.sitkNearestNeighbor)

            final_lblmap = (sitk.Cast(air_lm == 0, sitk.sitkUInt16) * head_lm) + air_lm

            orig_lm = read_and_chop_image(lbs_name, mincutoff)
            orig_lm = resample_256_iso(orig_lm, sitk.sitkNearestNeighbor)

            final_lblmap = sitk.Cast(fov_mask, sitk.sitkUInt16) * (
                    (sitk.Cast(orig_lm == 0, sitk.sitkUInt16) * final_lblmap) + orig_lm)

            LESION_VALUE = 600  # 600,Tumor,254,254,254,255  Tumor or lesion or otherwise unnatural brain abnormality structure

            lesion_files_found = []
            lesion_lm = final_lblmap * 0  # if the lesion_lbl_name does not exist, then assume no lesions
            for suffix in ['', '_1', '_2', '_3', '_4', '_5']:
                lesion_lbl_name = os.path.join(base_path, 'TissueClassify', 'lesion' + suffix + '_seg.nii.gz')
                if os.path.exists(lesion_lbl_name):
                    lesion_files_found.append(lesion_lbl_name)
                    lesion_section = read_and_chop_image(lesion_lbl_name, mincutoff)
                    lesion_section = sitk.Cast(resample_256_iso(lesion_section, sitk.sitkNearestNeighbor),
                                               sitk.sitkUInt16)
                    print("appending {0}".format(lesion_lbl_name))
                    lesion_lm = lesion_lm + lesion_section
                lesion_lm = sitk.Cast(lesion_lm > 0, sitk.sitkUInt16) * LESION_VALUE
            if not os.path.exists(lesion_cropped_link_name):
                print("Creating lesion segmentation: {0}".format(lesion_cropped_link_name))
                WriteImageUInt8(lesion_lm,lesion_cropped_link_name,False)
            final_lblmap = sitk.Cast(lesion_lm == 0, sitk.sitkUInt16) * final_lblmap + lesion_lm
            if not os.path.exists(lbs_link_name):
                final_lblmap = lblmap_renumber( final_lblmap, GLBL_BAW_TO_COMPACT_MAPPING );
                WriteImageUInt8(final_lblmap, lbs_link_name,False)
            lesion_list_name = os.path.join(OUT_DIR, "{0}_{1}_{2}".format(subj, sess, 'lesion_inputs.txt'))
            if len(lesion_files_found) > 0 and not os.path.exists(lesion_list_name):
                with open(lesion_list_name, 'w') as llfid:
                    for lin in lesion_files_found:
                      llfid.write("{0}\n".format(lin))
        t1w_masked_link_name = os.path.join(OUT_DIR, "{0}_{1}_{2}.nii.gz".format(subj, sess, 't1w_masked'))
        lbs_dense_compact_link_name = lbs_link_name # os.path.join(OUT_DIR, "{0}_{1}_{2}.nii.gz".format(subj, sess, 'dense_compact_seg'))
        if not os.path.exists(lbs_dense_compact_link_name) or not os.path.exists(t1w_masked_link_name):
            final_lblmap = sitk.ReadImage(lbs_dense_compact_link_name, sitk.sitkUInt16)
            mask = sitk.Cast( sitk.BinaryMorphologicalClosing(final_lblmap > 0, 3) > 0 , sitk.sitkUInt16 )
            t1w_masked = sitk.ReadImage(t1w_link_name, sitk.sitkUInt16)
            t1w_masked = mask * t1w_masked
            WriteImageUInt8(t1w_masked,t1w_masked_link_name, True)
            del t1w_masked, t1w_masked_link_name,t1w_name
            if os.path.exists(t2w_link_name):
                t2w_masked_link_name = os.path.join(OUT_DIR, "{0}_{1}_{2}.nii.gz".format(subj, sess, 't2w'))
                t2w_masked = sitk.ReadImage(t2w_link_name, sitk.sitkUInt16)
                t2w_masked = mask * t2w_masked
                WriteImageUInt8(t2w_masked, t2w_masked_link_name, True)
                del t2w_masked, t2w_masked_link_name
            del mask

if len(sys.argv) < 2:
    print("ERROR:  Missing command line arguments <Do generation> <Do make lists>")
    sys.exit(-1)

    ### HACK
all_base_baw_dirs=all_base_baw_dirs
if sys.argv[1] == '1':
    # Single threaded
    # for base_path in all_base_baw_dirs[0:50000]:
    #     process_one_session(base_path)
    # Parallel run
    results = Parallel(n_jobs=24)(
        delayed(process_one_session)(base_path) for base_path in all_base_baw_dirs)

print(sys.argv)


do_image_file_reading = False
if sys.argv[2] == '1':
    bad_data_files=list()
    good_data_files=list()
    print("COMPUTING SET OF LABELS")
    found_label_numbers = set([0]) # always ensure that zero is part of the set!
    lsif = sitk.LabelShapeStatisticsImageFilter()
    t1_dict = dict()
    seg_dict = dict()
    t1_mm_dict = dict()
    t2_mm_dict = dict()
    seg_mm_dict = dict()

    data_part = dict()
    index_counter = 0
    for base_path in all_base_baw_dirs:
        index_counter = index_counter + 1
        path_elements = base_path.split('/')
        # proj = path_elements[-]
        subj = path_elements[-2]
        sess = path_elements[-1]
        DATA_PARTITION="Training"
        if index_counter % 10 == 7: # 10% for validation
            DATA_PARTITION="Validation"
        if index_counter % 10 == 9 or index_counter % 10 == 8:  # 20% for inference hold out
            DATA_PARTITION="Inference"
        data_part[sess]=DATA_PARTITION
        t1w_cropped_link_name = os.path.join(OUT_DIR, "{0}_{1}_{2}.nii.gz".format(subj, sess, 't1w'))
        t2w_cropped_link_name = os.path.join(OUT_DIR, "{0}_{1}_{2}.nii.gz".format(subj, sess, 't2w'))
        lbs_link_name = os.path.join(OUT_DIR, "{0}_{1}_{2}.nii.gz".format(subj, sess, 'dense_seg'))
        lbs_dense_compact_link_name = lbs_link_name # os.path.join(OUT_DIR, "{0}_{1}_{2}.nii.gz".format(subj, sess, 'dense_compact_seg'))

        if os.path.exists(lbs_dense_compact_link_name):
            if do_image_file_reading:
                final = sitk.ReadImage(lbs_dense_compact_link_name, sitk.sitkUInt16)
                lsif.Execute(final)
                labels_found = set(lsif.GetLabels())
                new_found_label_numbers = found_label_numbers.union(labels_found)
                label_diff = new_found_label_numbers - found_label_numbers
                if do_image_file_reading and len(found_label_numbers) > 220 and len(label_diff) > 0 :
                    print("\nImage {0} added {1} unique labels {2}".format(lbs_dense_compact_link_name, len(label_diff), label_diff))
                    lbs_name = os.path.join(base_path, 'JointFusion', 'JointFusion_HDAtlas20_2015_dustCleaned_label.nii.gz')
                    head_lbls_name = os.path.join(base_path, 'TissueClassify', 'fixed_headlabels_seg.nii.gz')
                    air_lbl_name = os.path.join(base_path, 'TissueClassify', 'POSTERIOR_AIR.nii.gz')
                    print(" {0} \n{1}   \n{2}".format(lbs_name, head_lbls_name, air_lbl_name))
                    print(len(new_found_label_numbers))
                    bad_data_files.append(lbs_dense_compact_link_name)

            if os.path.exists(t1w_cropped_link_name) and os.path.exists(lbs_dense_compact_link_name):
                print("session: {0} {1}".format( sess, t1w_cropped_link_name))
                t1_dict[sess] = t1w_cropped_link_name
                seg_dict[sess] = lbs_dense_compact_link_name
                if os.path.exists(t2w_cropped_link_name):
                    t1_mm_dict[sess] = t1w_cropped_link_name
                    t2_mm_dict[sess] = t2w_cropped_link_name
                    seg_mm_dict[sess] = lbs_dense_compact_link_name
            else:
                print("MISSING: {0} or {1}".format(t1w_cropped_link_name, lbs_dense_compact_link_name))
            if do_image_file_reading:
                found_label_numbers = new_found_label_numbers
            good_data_files.append(lbs_dense_compact_link_name)
        else:
            print("MISSING: "+lbs_dense_compact_link_name)
    nifit_net_write_csv(WORK_DIR+'/allT1.csv', t1_dict)
    nifit_net_write_csv(WORK_DIR+'/allSeg.csv',seg_dict)
    nifit_net_write_csv(WORK_DIR+'/dataSplit.csv',data_part)

    nifit_net_write_csv(WORK_DIR + '/allT1_mm.csv', t1_mm_dict)
    nifit_net_write_csv(WORK_DIR + '/allT2_mm.csv', t2_mm_dict)
    nifit_net_write_csv(WORK_DIR + '/allSeg_mm.csv', seg_mm_dict)

    if do_image_file_reading:
        print(found_label_numbers)
        print(len(found_label_numbers))

    print("NUM_BAD_DATA: {0}".format(len(bad_data_files)))
    print("NUM_GOOD_DATA: {0}".format(len(good_data_files)))
